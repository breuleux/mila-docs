<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Software Frameworks &mdash; MILA Technical Documentation latest documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/documentation_options.js"></script>
        <script src="_static/documentation_options_fix.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Acknowledging Mila" href="Acknowledgement.html" />
    <link rel="prev" title="What is a computer cluster?" href="Theory_cluster.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/image.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Purpose.html">Purpose of this documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Purpose.html#contributing">Contributing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How-tos and Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Userguide.html">User’s guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Handbook.html">AI tooling and methodology handbook</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Systems and services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Information.html">Computing infrastructure and policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="Extra_compute.html">Computational resources outside of Mila</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">General theory</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html">What is a computer cluster?</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#parts-of-a-computing-cluster">Parts of a computing cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#unix">UNIX</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#the-workload-manager">The workload manager</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#processing-data">Processing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#software-on-the-cluster">Software on the cluster</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Minimal Examples</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Software Frameworks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pytorch-setup">PyTorch Setup</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#distributed-training">Distributed Training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#single-gpu-job">001 - Single GPU Job</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multi-gpu-job">002 - Multi-GPU Job</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multi-node-ddp-job">003 - Multi-Node (DDP) Job</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extras</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Acknowledgement.html">Acknowledging Mila</a></li>
<li class="toctree-l1"><a class="reference external" href="https://datasets.server.mila.quebec/">Mila Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="Audio_video.html">Audio and video resources at Mila</a></li>
<li class="toctree-l1"><a class="reference internal" href="VSCode.html">Visual Studio Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="IDT.html">Who, what, where is IDT</a></li>
<li class="toctree-l1"><a class="reference internal" href="Chatbot.html">Chatbot for Mila</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MILA Technical Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Software Frameworks</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/mila-iqia/mila-docs/blob/master/docs/Minimal_examples.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="software-frameworks">
<h1>Software Frameworks<a class="headerlink" href="#software-frameworks" title="Permalink to this heading"></a></h1>
<section id="pytorch-setup">
<span id="id1"></span><h2>PyTorch Setup<a class="headerlink" href="#pytorch-setup" title="Permalink to this heading"></a></h2>
<p><strong>Prerequisites</strong>: (Make sure to read the following before using this example!)</p>
<ul class="simple">
<li><p><a class="reference internal" href="Userguide.html#quick-start"><span class="std std-ref">Quick Start</span></a></p></li>
<li><p><a class="reference internal" href="Userguide.html#running-your-code"><span class="std std-ref">Running your code</span></a></p></li>
<li><p><a class="reference internal" href="Userguide.html#conda"><span class="std std-ref">Conda</span></a></p></li>
</ul>
<p><strong>job.sh</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --cpus-per-task=1</span>
<span class="c1">#SBATCH --mem=16G</span>
<span class="c1">#SBATCH --time=00:15:00</span>
<span class="c1">#SBATCH --partition=unkillable</span>

<span class="nb">set</span><span class="w"> </span>-e<span class="w">  </span><span class="c1"># exit on error.</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Date:     </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Hostname: </span><span class="k">$(</span>hostname<span class="k">)</span><span class="s2">&quot;</span>

module<span class="w"> </span>purge
<span class="c1"># This example uses Conda to manage package dependencies.</span>
<span class="c1"># See https://docs.mila.quebec/Userguide.html#conda for more information.</span>
module<span class="w"> </span>load<span class="w"> </span>anaconda/3

<span class="c1"># Creating the environment for the first time:</span>
<span class="c1"># conda create -y -n pytorch python=3.9 pytorch torchvision torchaudio \</span>
<span class="c1">#     pytorch-cuda=11.6 -c pytorch -c nvidia</span>
<span class="c1"># Other conda packages:</span>
<span class="c1"># conda install -y -n pytorch -c conda-forge rich</span>

<span class="c1"># Activate the environment:</span>
conda<span class="w"> </span>activate<span class="w"> </span>pytorch

<span class="c1"># Fixes issues with MIG-ed GPUs with versions of PyTorch &lt; 2.0</span>
<span class="nb">unset</span><span class="w"> </span>CUDA_VISIBLE_DEVICES

python<span class="w"> </span>main.py
</pre></div>
</div>
<p><strong>main.py</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.backends.cuda</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">cuda_built</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_built</span><span class="p">()</span>
    <span class="n">cuda_avail</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="n">device_count</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch built with CUDA:         </span><span class="si">{</span><span class="n">cuda_built</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch detects CUDA available:  </span><span class="si">{</span><span class="n">cuda_avail</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch-detected #GPUs:          </span><span class="si">{</span><span class="n">device_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">device_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    No GPU detected, not printing devices&#39; names.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">device_count</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    GPU </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">:      </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Running this example</strong></p>
<p>This assumes that you already created a conda environment named “pytorch”. To
create this environment, we first request resources for an interactive job.
Note that we are requesting a GPU for this job, even though we’re only going to
install packages. This is because we want PyTorch to be installed with GPU
support, and to have all the required libraries.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>salloc<span class="w"> </span>--gres<span class="o">=</span>gpu:1<span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--mem<span class="o">=</span>16G<span class="w"> </span>--time<span class="o">=</span><span class="m">00</span>:30:00
salloc:<span class="w"> </span>--------------------------------------------------------------------------------------------------
salloc:<span class="w"> </span><span class="c1"># Using default long partition</span>
salloc:<span class="w"> </span>--------------------------------------------------------------------------------------------------
salloc:<span class="w"> </span>Pending<span class="w"> </span>job<span class="w"> </span>allocation<span class="w"> </span><span class="m">2959785</span>
salloc:<span class="w"> </span>job<span class="w"> </span><span class="m">2959785</span><span class="w"> </span>queued<span class="w"> </span>and<span class="w"> </span>waiting<span class="w"> </span><span class="k">for</span><span class="w"> </span>resources
salloc:<span class="w"> </span>job<span class="w"> </span><span class="m">2959785</span><span class="w"> </span>has<span class="w"> </span>been<span class="w"> </span>allocated<span class="w"> </span>resources
salloc:<span class="w"> </span>Granted<span class="w"> </span>job<span class="w"> </span>allocation<span class="w"> </span><span class="m">2959785</span>
salloc:<span class="w"> </span>Waiting<span class="w"> </span><span class="k">for</span><span class="w"> </span>resource<span class="w"> </span>configuration
salloc:<span class="w"> </span>Nodes<span class="w"> </span>cn-g022<span class="w"> </span>are<span class="w"> </span>ready<span class="w"> </span><span class="k">for</span><span class="w"> </span>job
$<span class="w"> </span><span class="c1"># Create the environment (see the example):</span>
$<span class="w"> </span>conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>pytorch<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.9<span class="w"> </span>pytorch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio<span class="w"> </span>pytorch-cuda<span class="o">=</span><span class="m">11</span>.7<span class="w"> </span>-c<span class="w"> </span>pytorch<span class="w"> </span>-c<span class="w"> </span>nvidia
<span class="o">(</span>...<span class="o">)</span>
$<span class="w"> </span><span class="c1"># Press &#39;y&#39; to accept if everything looks good.</span>
<span class="o">(</span>...<span class="o">)</span>
$<span class="w"> </span><span class="c1"># Activate the environment:</span>
$<span class="w"> </span>conda<span class="w"> </span>activate<span class="w"> </span>pytorch
</pre></div>
</div>
<p>Exit the interactive job once the environment has been created. Then, the
example can be launched to confirm that everything works:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sbatch<span class="w"> </span>job.sh
</pre></div>
</div>
</section>
</section>
<section id="distributed-training">
<h1>Distributed Training<a class="headerlink" href="#distributed-training" title="Permalink to this heading"></a></h1>
<section id="single-gpu-job">
<h2>001 - Single GPU Job<a class="headerlink" href="#single-gpu-job" title="Permalink to this heading"></a></h2>
<p><strong>Prerequisites</strong>
Make sure to read the following sections of the documentation before using this
example:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#pytorch-setup"><span class="std std-ref">PyTorch Setup</span></a></p></li>
</ul>
<p>The full source code for this example is available on <a class="reference external" href="https://github.com/mila-iqia/mila-docs/tree/pytorch_distributed_training_examples/docs/examples/distributed/001_single_gpu">the mila-docs GitHub
repository.</a></p>
<p><strong>job.sh</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --gpus-per-task=rtx8000:1</span>
<span class="c1">#SBATCH --cpus-per-task=4</span>
<span class="c1">#SBATCH --ntasks-per-node=1</span>
<span class="c1">#SBATCH --mem=16G</span>
<span class="c1">#SBATCH --time=00:15:00</span>


<span class="c1"># Echo time and hostname into log</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Date:     </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Hostname: </span><span class="k">$(</span>hostname<span class="k">)</span><span class="s2">&quot;</span>


<span class="c1"># Ensure only anaconda/3 module loaded.</span>
module<span class="w"> </span>--quiet<span class="w"> </span>purge
<span class="c1"># This example uses Conda to manage package dependencies.</span>
<span class="c1"># See https://docs.mila.quebec/Userguide.html#conda for more information.</span>
module<span class="w"> </span>load<span class="w"> </span>anaconda/3
module<span class="w"> </span>load<span class="w"> </span>cuda/11.7

<span class="c1"># Creating the environment for the first time:</span>
<span class="c1"># conda create -y -n pytorch python=3.9 pytorch torchvision torchaudio \</span>
<span class="c1">#     pytorch-cuda=11.7 -c pytorch -c nvidia</span>
<span class="c1"># Other conda packages:</span>
<span class="c1"># conda install -y -n pytorch -c conda-forge rich tqdm</span>

<span class="c1"># Activate pre-existing environment.</span>
conda<span class="w"> </span>activate<span class="w"> </span>pytorch


<span class="c1"># Stage dataset into $SLURM_TMPDIR</span>
mkdir<span class="w"> </span>-p<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/data
cp<span class="w"> </span>/network/datasets/cifar10/cifar-10-python.tar.gz<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/data/
<span class="c1"># General-purpose alternatives combining copy and unpack:</span>
<span class="c1">#     unzip   /network/datasets/some/file.zip -d $SLURM_TMPDIR/data/</span>
<span class="c1">#     tar -xf /network/datasets/some/file.tar -C $SLURM_TMPDIR/data/</span>


<span class="c1"># Fixes issues with MIG-ed GPUs with versions of PyTorch &lt; 2.0</span>
<span class="nb">unset</span><span class="w"> </span>CUDA_VISIBLE_DEVICES

<span class="c1"># Execute Python script</span>
python<span class="w"> </span>main.py
</pre></div>
</div>
<p><strong>main.py</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Single-GPU training example.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">rich.logging</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">CIFAR10</span>
<span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">resnet18</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">5e-4</span>
    <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

    <span class="c1"># Check that the GPU is available</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Setup logging (optional, but much better than using print statements)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
        <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
        <span class="n">handlers</span><span class="o">=</span><span class="p">[</span><span class="n">rich</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">RichHandler</span><span class="p">(</span><span class="n">markup</span><span class="o">=</span><span class="kc">True</span><span class="p">)],</span>  <span class="c1"># Very pretty, uses the `rich` package.</span>
    <span class="p">)</span>

    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

    <span class="c1"># Create a model and move it to the GPU.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

    <span class="c1"># Setup CIFAR10</span>
    <span class="n">num_workers</span> <span class="o">=</span> <span class="n">get_num_workers</span><span class="p">()</span>
    <span class="n">dataset_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;SLURM_TMPDIR&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="p">))</span> <span class="o">/</span> <span class="s2">&quot;data&quot;</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">make_datasets</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">))</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">valid_dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>  <span class="c1"># NOTE: Not used in this example.</span>
        <span class="n">test_dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Checkout the &quot;checkpointing and preemption&quot; example for more info!</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Starting training from scratch.&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">training_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Set the model in training mode (important for e.g. BatchNorm and Dropout layers)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># NOTE: using a progress bar from tqdm because it&#39;s nicer than using `print`.</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span>
            <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
            <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Train epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Training loop</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
            <span class="c1"># Move the batch to the GPU before we pass it to the model</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

            <span class="c1"># Forward pass</span>
            <span class="n">logits</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Calculate some metrics:</span>
            <span class="n">n_correct_predictions</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">n_samples</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">n_correct_predictions</span> <span class="o">/</span> <span class="n">n_samples</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Advance the progress bar one step, and update the &quot;postfix&quot; () the progress bar. (nicer than just)</span>
            <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">validation_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: Val loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done!&quot;</span><span class="p">)</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">validation_loop</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct_predictions</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="n">logits</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">batch_n_samples</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">batch_correct_predictions</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">n_samples</span> <span class="o">+=</span> <span class="n">batch_n_samples</span>
        <span class="n">correct_predictions</span> <span class="o">+=</span> <span class="n">batch_correct_predictions</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct_predictions</span> <span class="o">/</span> <span class="n">n_samples</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">accuracy</span>


<span class="k">def</span> <span class="nf">make_datasets</span><span class="p">(</span>
    <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">val_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">val_split_seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the training, validation, and test splits for CIFAR10.</span>

<span class="sd">    NOTE: We don&#39;t use image transforms here for simplicity.</span>
<span class="sd">    Having different transformations for train and validation would complicate things a bit.</span>
<span class="sd">    Later examples will show how to do the train/val/test split properly when using transforms.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="c1"># Split the training dataset into a training and validation set.</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
    <span class="n">n_valid</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">val_split</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="n">n_train</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_valid</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="p">,</span> <span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_valid</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">val_split_seed</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>


<span class="k">def</span> <span class="nf">get_num_workers</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gets the optimal number of DatLoader workers to use in the current job.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s2">&quot;SLURM_CPUS_PER_TASK&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;SLURM_CPUS_PER_TASK&quot;</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">os</span><span class="p">,</span> <span class="s2">&quot;sched_getaffinity&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">sched_getaffinity</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Running this example</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sbatch<span class="w"> </span>job.sh
</pre></div>
</div>
</section>
<section id="multi-gpu-job">
<h2>002 - Multi-GPU Job<a class="headerlink" href="#multi-gpu-job" title="Permalink to this heading"></a></h2>
<p>Prerequisites:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#pytorch-setup"><span class="std std-ref">PyTorch Setup</span></a></p></li>
<li><p><a class="reference internal" href="#single-gpu-job"><span class="std std-ref">001 - Single GPU Job</span></a></p></li>
</ul>
<p>Other interesting resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://sebarnold.net/dist_blog/">https://sebarnold.net/dist_blog/</a></p></li>
<li><p><a class="reference external" href="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide</a></p></li>
</ul>
<p>Click here to see <a class="reference external" href="https://github.com/mila-iqia/mila-docs/tree/master/docs/examples/distributed/002_multi_gpu">the code for this example</a></p>
<p><strong>Job.sh</strong></p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="w"> </span># distributed/001_single_gpu/job.sh -&gt; distributed/002_multi_gpu/job.sh
<span class="w"> </span>#!/bin/bash
<span class="w"> </span>#SBATCH --gpus-per-task=rtx8000:1
<span class="w"> </span>#SBATCH --cpus-per-task=4
<span class="gd">-#SBATCH --ntasks-per-node=1</span>
<span class="gi">+#SBATCH --ntasks-per-node=4</span>
<span class="w"> </span>#SBATCH --mem=16G
<span class="w"> </span>#SBATCH --time=00:15:00
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span># Echo time and hostname into log
<span class="w"> </span>echo &quot;Date:     $(date)&quot;
<span class="w"> </span>echo &quot;Hostname: $(hostname)&quot;
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span># Ensure only anaconda/3 module loaded.
<span class="w"> </span>module --quiet purge
<span class="w"> </span># This example uses Conda to manage package dependencies.
<span class="w"> </span># See https://docs.mila.quebec/Userguide.html#conda for more information.
<span class="w"> </span>module load anaconda/3
<span class="w"> </span>module load cuda/11.7
<span class="w"> </span>
<span class="w"> </span># Creating the environment for the first time:
<span class="w"> </span># conda create -y -n pytorch python=3.9 pytorch torchvision torchaudio \
<span class="w"> </span>#     pytorch-cuda=11.7 -c pytorch -c nvidia
<span class="w"> </span># Other conda packages:
<span class="w"> </span># conda install -y -n pytorch -c conda-forge rich tqdm
<span class="w"> </span>
<span class="w"> </span># Activate pre-existing environment.
<span class="w"> </span>conda activate pytorch
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span># Stage dataset into $SLURM_TMPDIR
<span class="w"> </span>mkdir -p $SLURM_TMPDIR/data
<span class="gd">-cp /network/datasets/cifar10/cifar-10-python.tar.gz $SLURM_TMPDIR/data/</span>
<span class="gd">-# General-purpose alternatives combining copy and unpack:</span>
<span class="gd">-#     unzip   /network/datasets/some/file.zip -d $SLURM_TMPDIR/data/</span>
<span class="gd">-#     tar -xf /network/datasets/some/file.tar -C $SLURM_TMPDIR/data/</span>
<span class="gi">+ln -s /network/datasets/cifar10/cifar-10-python.tar.gz $SLURM_TMPDIR/data/</span>
<span class="w"> </span>
<span class="gi">+# Get a unique port for this job based on the job ID</span>
<span class="gi">+export MASTER_PORT=$(expr 10000 + $(echo -n $SLURM_JOBID | tail -c 4))</span>
<span class="gi">+export MASTER_ADDR=&quot;127.0.0.1&quot;</span>
<span class="w"> </span>
<span class="w"> </span># Fixes issues with MIG-ed GPUs with versions of PyTorch &lt; 2.0
<span class="w"> </span>unset CUDA_VISIBLE_DEVICES
<span class="w"> </span>
<span class="gd">-# Execute Python script</span>
<span class="gd">-python main.py</span>
<span class="gi">+# Execute Python script in each task (one per GPU)</span>
<span class="gi">+srun python main.py</span>
</pre></div>
</div>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="w"> </span># distributed/001_single_gpu/main.py -&gt; distributed/002_multi_gpu/main.py
<span class="gd">-&quot;&quot;&quot;Single-GPU training example.&quot;&quot;&quot;</span>
<span class="gi">+&quot;&quot;&quot;Multi-GPU Training example.&quot;&quot;&quot;</span>
<span class="w"> </span>import logging
<span class="w"> </span>import os
<span class="w"> </span>from pathlib import Path
<span class="w"> </span>
<span class="w"> </span>import rich.logging
<span class="w"> </span>import torch
<span class="gi">+import torch.distributed</span>
<span class="w"> </span>from torch import Tensor, nn
<span class="gi">+from torch.distributed import ReduceOp</span>
<span class="w"> </span>from torch.nn import functional as F
<span class="w"> </span>from torch.utils.data import DataLoader, random_split
<span class="gi">+from torch.utils.data.distributed import DistributedSampler</span>
<span class="w"> </span>from torchvision import transforms
<span class="w"> </span>from torchvision.datasets import CIFAR10
<span class="w"> </span>from torchvision.models import resnet18
<span class="w"> </span>from tqdm import tqdm
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>def main():
<span class="w"> </span>    training_epochs = 10
<span class="w"> </span>    learning_rate = 5e-4
<span class="w"> </span>    weight_decay = 1e-4
<span class="gd">-    batch_size = 128</span>
<span class="gi">+    batch_size = 128  # NOTE: This is the &quot;local&quot; batch size, per-GPU.</span>
<span class="w"> </span>
<span class="w"> </span>    # Check that the GPU is available
<span class="w"> </span>    assert torch.cuda.is_available() and torch.cuda.device_count() &gt; 0
<span class="gd">-    device = torch.device(&quot;cuda&quot;, 0)</span>
<span class="gi">+    rank, world_size = setup()</span>
<span class="gi">+    is_master = rank == 0</span>
<span class="gi">+    device = torch.device(&quot;cuda&quot;, rank)</span>
<span class="w"> </span>
<span class="w"> </span>    # Setup logging (optional, but much better than using print statements)
<span class="w"> </span>    logging.basicConfig(
<span class="w"> </span>        level=logging.INFO,
<span class="gi">+        format=f&quot;[{rank}/{world_size}] %(name)s - %(message)s &quot;,</span>
<span class="w"> </span>        handlers=[rich.logging.RichHandler(markup=True)],  # Very pretty, uses the `rich` package.
<span class="w"> </span>    )
<span class="w"> </span>
<span class="w"> </span>    logger = logging.getLogger(__name__)
<span class="gi">+    logger.info(f&quot;World size: {world_size}, global rank: {rank}&quot;)</span>
<span class="w"> </span>
<span class="w"> </span>    # Create a model and move it to the GPU.
<span class="w"> </span>    model = resnet18(num_classes=10)
<span class="w"> </span>    model.to(device=device)
<span class="w"> </span>
<span class="gi">+    # Wrap the model with DistributedDataParallel</span>
<span class="gi">+    # (See https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel)</span>
<span class="gi">+    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank], output_device=rank)</span>
<span class="gi">+</span>
<span class="w"> </span>    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
<span class="w"> </span>
<span class="w"> </span>    # Setup CIFAR10
<span class="w"> </span>    num_workers = get_num_workers()
<span class="w"> </span>    dataset_path = Path(os.environ.get(&quot;SLURM_TMPDIR&quot;, &quot;.&quot;)) / &quot;data&quot;
<span class="gd">-    train_dataset, valid_dataset, test_dataset = make_datasets(str(dataset_path))</span>
<span class="gi">+    train_dataset, valid_dataset, test_dataset = make_datasets(</span>
<span class="gi">+        str(dataset_path), is_master=is_master</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # Restricts data loading to a subset of the dataset exclusive to the current process</span>
<span class="gi">+    train_sampler = DistributedSampler(dataset=train_dataset, shuffle=True)</span>
<span class="gi">+    valid_sampler = DistributedSampler(dataset=valid_dataset, shuffle=False)</span>
<span class="gi">+    test_sampler = DistributedSampler(dataset=test_dataset, shuffle=False)</span>
<span class="gi">+</span>
<span class="gi">+    # NOTE: Here `batch_size` is still the &quot;local&quot; (per-gpu) batch size.</span>
<span class="gi">+    # This way, the effective batch size scales directly with number of GPUs, no need to specify it</span>
<span class="gi">+    # in advance. You might want to adjust the learning rate and other hyper-parameters though.</span>
<span class="gi">+    if is_master:</span>
<span class="gi">+        logger.info(f&quot;Effective batch size: {batch_size * world_size}&quot;)</span>
<span class="w"> </span>    train_dataloader = DataLoader(
<span class="w"> </span>        train_dataset,
<span class="w"> </span>        batch_size=batch_size,
<span class="w"> </span>        num_workers=num_workers,
<span class="gd">-        shuffle=True,</span>
<span class="gi">+        shuffle=False,  # shuffling is now done in the sampler, not the dataloader.</span>
<span class="gi">+        sampler=train_sampler,</span>
<span class="w"> </span>    )
<span class="w"> </span>    valid_dataloader = DataLoader(
<span class="w"> </span>        valid_dataset,
<span class="w"> </span>        batch_size=batch_size,
<span class="w"> </span>        num_workers=num_workers,
<span class="w"> </span>        shuffle=False,
<span class="gi">+        sampler=valid_sampler,</span>
<span class="w"> </span>    )
<span class="w"> </span>    test_dataloader = DataLoader(  # NOTE: Not used in this example.
<span class="w"> </span>        test_dataset,
<span class="w"> </span>        batch_size=batch_size,
<span class="w"> </span>        num_workers=num_workers,
<span class="w"> </span>        shuffle=False,
<span class="gi">+        sampler=test_sampler,</span>
<span class="w"> </span>    )
<span class="w"> </span>
<span class="w"> </span>    # Checkout the &quot;checkpointing and preemption&quot; example for more info!
<span class="w"> </span>    logger.debug(&quot;Starting training from scratch.&quot;)
<span class="w"> </span>
<span class="w"> </span>    for epoch in range(training_epochs):
<span class="w"> </span>        logger.debug(f&quot;Starting epoch {epoch}/{training_epochs}&quot;)
<span class="w"> </span>
<span class="gi">+        # NOTE: Here we need to call `set_epoch` so the ordering is able to change at each epoch.</span>
<span class="gi">+        train_sampler.set_epoch(epoch)</span>
<span class="gi">+</span>
<span class="w"> </span>        # Set the model in training mode (important for e.g. BatchNorm and Dropout layers)
<span class="w"> </span>        model.train()
<span class="w"> </span>
<span class="w"> </span>        # NOTE: using a progress bar from tqdm because it&#39;s nicer than using `print`.
<span class="w"> </span>        progress_bar = tqdm(
<span class="w"> </span>            total=len(train_dataloader),
<span class="w"> </span>            desc=f&quot;Train epoch {epoch}&quot;,
<span class="gi">+            disable=not is_master,</span>
<span class="w"> </span>        )
<span class="w"> </span>
<span class="w"> </span>        # Training loop
<span class="w"> </span>        for batch in train_dataloader:
<span class="w"> </span>            # Move the batch to the GPU before we pass it to the model
<span class="w"> </span>            batch = tuple(item.to(device) for item in batch)
<span class="w"> </span>            x, y = batch
<span class="w"> </span>
<span class="w"> </span>            # Forward pass
<span class="w"> </span>            logits: Tensor = model(x)
<span class="w"> </span>
<span class="gd">-            loss = F.cross_entropy(logits, y)</span>
<span class="gi">+            local_loss = F.cross_entropy(logits, y)</span>
<span class="w"> </span>
<span class="w"> </span>            optimizer.zero_grad()
<span class="gd">-            loss.backward()</span>
<span class="gi">+            local_loss.backward()</span>
<span class="gi">+            # NOTE: nn.DistributedDataParallel automatically averages the gradients across devices.</span>
<span class="w"> </span>            optimizer.step()
<span class="w"> </span>
<span class="w"> </span>            # Calculate some metrics:
<span class="gd">-            n_correct_predictions = logits.detach().argmax(-1).eq(y).sum()</span>
<span class="gd">-            n_samples = y.shape[0]</span>
<span class="gi">+            # local metrics</span>
<span class="gi">+            local_n_correct_predictions = logits.detach().argmax(-1).eq(y).sum()</span>
<span class="gi">+            local_n_samples = logits.shape[0]</span>
<span class="gi">+            local_accuracy = local_n_correct_predictions / local_n_samples</span>
<span class="gi">+</span>
<span class="gi">+            # &quot;global&quot; metrics: calculated with the results from all workers</span>
<span class="gi">+            # NOTE: Creating new tensors to hold the &quot;global&quot; values, but this isn&#39;t required.</span>
<span class="gi">+            n_correct_predictions = local_n_correct_predictions.clone()</span>
<span class="gi">+            # Reduce the local metrics across all workers, sending the result to rank 0.</span>
<span class="gi">+            torch.distributed.reduce(n_correct_predictions, dst=0, op=ReduceOp.SUM)</span>
<span class="gi">+            # Actual (global) batch size for this step.</span>
<span class="gi">+            n_samples = torch.as_tensor(local_n_samples, device=device)</span>
<span class="gi">+            torch.distributed.reduce(n_samples, dst=0, op=ReduceOp.SUM)</span>
<span class="gi">+            # Will store the average loss across all workers.</span>
<span class="gi">+            loss = local_loss.clone()</span>
<span class="gi">+            torch.distributed.reduce(loss, dst=0, op=ReduceOp.SUM)</span>
<span class="gi">+            loss.div_(world_size)  # Report the average loss across all workers.</span>
<span class="gi">+</span>
<span class="w"> </span>            accuracy = n_correct_predictions / n_samples
<span class="w"> </span>
<span class="gd">-            logger.debug(f&quot;Accuracy: {accuracy.item():.2%}&quot;)</span>
<span class="gd">-            logger.debug(f&quot;Average Loss: {loss.item()}&quot;)</span>
<span class="gi">+            logger.debug(f&quot;(local) Accuracy: {local_accuracy:.2%}&quot;)</span>
<span class="gi">+            logger.debug(f&quot;(local) Loss: {local_loss.item()}&quot;)</span>
<span class="gi">+            # NOTE: This would log the same values in all workers. Only logging on master:</span>
<span class="gi">+            if is_master:</span>
<span class="gi">+                logger.debug(f&quot;Accuracy: {accuracy.item():.2%}&quot;)</span>
<span class="gi">+                logger.debug(f&quot;Average Loss: {loss.item()}&quot;)</span>
<span class="w"> </span>
<span class="w"> </span>            # Advance the progress bar one step, and update the &quot;postfix&quot; () the progress bar. (nicer than just)
<span class="w"> </span>            progress_bar.update(1)
<span class="w"> </span>            progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy.item())
<span class="w"> </span>        progress_bar.close()
<span class="w"> </span>
<span class="w"> </span>        val_loss, val_accuracy = validation_loop(model, valid_dataloader, device)
<span class="gd">-        logger.info(f&quot;Epoch {epoch}: Val loss: {val_loss:.3f} accuracy: {val_accuracy:.2%}&quot;)</span>
<span class="gi">+        # NOTE: This would log the same values in all workers. Only logging on master:</span>
<span class="gi">+        if is_master:</span>
<span class="gi">+            logger.info(f&quot;Epoch {epoch}: Val loss: {val_loss:.3f} accuracy: {val_accuracy:.2%}&quot;)</span>
<span class="w"> </span>
<span class="w"> </span>    print(&quot;Done!&quot;)
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>@torch.no_grad()
<span class="w"> </span>def validation_loop(model: nn.Module, dataloader: DataLoader, device: torch.device):
<span class="w"> </span>    model.eval()
<span class="w"> </span>
<span class="gd">-    total_loss = 0.0</span>
<span class="gd">-    n_samples = 0</span>
<span class="gd">-    correct_predictions = 0</span>
<span class="gi">+    total_loss = torch.as_tensor(0.0, device=device)</span>
<span class="gi">+    n_samples = torch.as_tensor(0, device=device)</span>
<span class="gi">+    correct_predictions = torch.as_tensor(0, device=device)</span>
<span class="w"> </span>
<span class="w"> </span>    for batch in dataloader:
<span class="w"> </span>        batch = tuple(item.to(device) for item in batch)
<span class="w"> </span>        x, y = batch
<span class="w"> </span>
<span class="w"> </span>        logits: Tensor = model(x)
<span class="w"> </span>        loss = F.cross_entropy(logits, y)
<span class="w"> </span>
<span class="w"> </span>        batch_n_samples = x.shape[0]
<span class="w"> </span>        batch_correct_predictions = logits.argmax(-1).eq(y).sum()
<span class="w"> </span>
<span class="gd">-        total_loss += loss.item()</span>
<span class="gi">+        total_loss += loss</span>
<span class="w"> </span>        n_samples += batch_n_samples
<span class="w"> </span>        correct_predictions += batch_correct_predictions
<span class="w"> </span>
<span class="gi">+    # Sum up the metrics we gathered on each worker before returning the overall val metrics.</span>
<span class="gi">+    torch.distributed.all_reduce(total_loss, op=torch.distributed.ReduceOp.SUM)</span>
<span class="gi">+    torch.distributed.all_reduce(correct_predictions, op=torch.distributed.ReduceOp.SUM)</span>
<span class="gi">+    torch.distributed.all_reduce(n_samples, op=torch.distributed.ReduceOp.SUM)</span>
<span class="gi">+</span>
<span class="w"> </span>    accuracy = correct_predictions / n_samples
<span class="w"> </span>    return total_loss, accuracy
<span class="w"> </span>
<span class="w"> </span>
<span class="gi">+def setup():</span>
<span class="gi">+    assert torch.distributed.is_available()</span>
<span class="gi">+    print(&quot;PyTorch Distributed available.&quot;)</span>
<span class="gi">+    print(&quot;  Backends:&quot;)</span>
<span class="gi">+    print(f&quot;    Gloo: {torch.distributed.is_gloo_available()}&quot;)</span>
<span class="gi">+    print(f&quot;    NCCL: {torch.distributed.is_nccl_available()}&quot;)</span>
<span class="gi">+    print(f&quot;    MPI:  {torch.distributed.is_mpi_available()}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # DDP Job is being run via `srun` on a slurm cluster.</span>
<span class="gi">+    rank = int(os.environ[&quot;SLURM_PROCID&quot;])</span>
<span class="gi">+    world_size = int(os.environ[&quot;SLURM_NTASKS&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    # SLURM var -&gt; torch.distributed vars in case needed</span>
<span class="gi">+    # NOTE: Setting these values isn&#39;t exactly necessary, but some code might assume it&#39;s</span>
<span class="gi">+    # being run via torchrun or torch.distributed.launch, so setting these can be a good idea.</span>
<span class="gi">+    os.environ[&quot;RANK&quot;] = str(rank)</span>
<span class="gi">+    os.environ[&quot;WORLD_SIZE&quot;] = str(world_size)</span>
<span class="gi">+</span>
<span class="gi">+    torch.distributed.init_process_group(</span>
<span class="gi">+        backend=&quot;nccl&quot;,</span>
<span class="gi">+        init_method=&quot;env://&quot;,</span>
<span class="gi">+        world_size=world_size,</span>
<span class="gi">+        rank=rank,</span>
<span class="gi">+    )</span>
<span class="gi">+    return rank, world_size</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>def make_datasets(
<span class="w"> </span>    dataset_path: str,
<span class="gi">+    is_master: bool,</span>
<span class="w"> </span>    val_split: float = 0.1,
<span class="w"> </span>    val_split_seed: int = 42,
<span class="w"> </span>):
<span class="w"> </span>    &quot;&quot;&quot;Returns the training, validation, and test splits for CIFAR10.
<span class="w"> </span>
<span class="w"> </span>    NOTE: We don&#39;t use image transforms here for simplicity.
<span class="w"> </span>    Having different transformations for train and validation would complicate things a bit.
<span class="w"> </span>    Later examples will show how to do the train/val/test split properly when using transforms.
<span class="gi">+</span>
<span class="gi">+    NOTE: Only the master process (rank-0) downloads the dataset if necessary.</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gi">+    # - Master: Download (if necessary) THEN Barrier</span>
<span class="gi">+    # - others: Barrier THEN *NO* Download</span>
<span class="gi">+    if not is_master:</span>
<span class="gi">+        # Wait for the master process to finish downloading (reach the barrier below)</span>
<span class="gi">+        torch.distributed.barrier()</span>
<span class="w"> </span>    train_dataset = CIFAR10(
<span class="gd">-        root=dataset_path, transform=transforms.ToTensor(), download=True, train=True</span>
<span class="gi">+        root=dataset_path, transform=transforms.ToTensor(), download=is_master, train=True</span>
<span class="w"> </span>    )
<span class="w"> </span>    test_dataset = CIFAR10(
<span class="gd">-        root=dataset_path, transform=transforms.ToTensor(), download=True, train=False</span>
<span class="gi">+        root=dataset_path, transform=transforms.ToTensor(), download=is_master, train=False</span>
<span class="w"> </span>    )
<span class="gi">+    if is_master:</span>
<span class="gi">+        # Join the workers waiting in the barrier above. They can now load the datasets from disk.</span>
<span class="gi">+        torch.distributed.barrier()</span>
<span class="w"> </span>    # Split the training dataset into a training and validation set.
<span class="w"> </span>    n_samples = len(train_dataset)
<span class="w"> </span>    n_valid = int(val_split * n_samples)
<span class="w"> </span>    n_train = n_samples - n_valid
<span class="w"> </span>    train_dataset, valid_dataset = random_split(
<span class="w"> </span>        train_dataset, (n_train, n_valid), torch.Generator().manual_seed(val_split_seed)
<span class="w"> </span>    )
<span class="w"> </span>    return train_dataset, valid_dataset, test_dataset
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>def get_num_workers() -&gt; int:
<span class="w"> </span>    &quot;&quot;&quot;Gets the optimal number of DatLoader workers to use in the current job.&quot;&quot;&quot;
<span class="w"> </span>    if &quot;SLURM_CPUS_PER_TASK&quot; in os.environ:
<span class="w"> </span>        return int(os.environ[&quot;SLURM_CPUS_PER_TASK&quot;])
<span class="w"> </span>    if hasattr(os, &quot;sched_getaffinity&quot;):
<span class="w"> </span>        return len(os.sched_getaffinity(0))
<span class="w"> </span>    return torch.multiprocessing.cpu_count()
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>if __name__ == &quot;__main__&quot;:
<span class="w"> </span>    main()
</pre></div>
</div>
<p><strong>Running this example</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sbatch<span class="w"> </span>job.sh
</pre></div>
</div>
</section>
<section id="multi-node-ddp-job">
<h2>003 - Multi-Node (DDP) Job<a class="headerlink" href="#multi-node-ddp-job" title="Permalink to this heading"></a></h2>
<p>Prerequisites:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#pytorch-setup"><span class="std std-ref">PyTorch Setup</span></a></p></li>
<li><p><a class="reference internal" href="#single-gpu-job"><span class="std std-ref">001 - Single GPU Job</span></a></p></li>
<li><p><a class="reference internal" href="#multi-gpu-job"><span class="std std-ref">002 - Multi-GPU Job</span></a></p></li>
</ul>
<p>Other interesting resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://sebarnold.net/dist_blog/">https://sebarnold.net/dist_blog/</a></p></li>
<li><p><a class="reference external" href="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide</a></p></li>
</ul>
<p>Click here to see <a class="reference external" href="https://github.com/mila-iqia/mila-docs/tree/master/docs/examples/distributed/003_multi_node">the source code for this example</a></p>
<p><strong>Job.sh</strong></p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="w"> </span># distributed/002_multi_gpu/job.sh -&gt; distributed/003_multi_node/job.sh
<span class="w"> </span>#!/bin/bash
<span class="w"> </span>#SBATCH --gpus-per-task=rtx8000:1
<span class="w"> </span>#SBATCH --cpus-per-task=4
<span class="w"> </span>#SBATCH --ntasks-per-node=4
<span class="gi">+#SBATCH --nodes=2</span>
<span class="w"> </span>#SBATCH --mem=16G
<span class="w"> </span>#SBATCH --time=00:15:00
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span># Echo time and hostname into log
<span class="w"> </span>echo &quot;Date:     $(date)&quot;
<span class="w"> </span>echo &quot;Hostname: $(hostname)&quot;
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span># Ensure only anaconda/3 module loaded.
<span class="w"> </span>module --quiet purge
<span class="w"> </span># This example uses Conda to manage package dependencies.
<span class="w"> </span># See https://docs.mila.quebec/Userguide.html#conda for more information.
<span class="w"> </span>module load anaconda/3
<span class="w"> </span>module load cuda/11.7
<span class="w"> </span>
<span class="w"> </span># Creating the environment for the first time:
<span class="w"> </span># conda create -y -n pytorch python=3.9 pytorch torchvision torchaudio \
<span class="w"> </span>#     pytorch-cuda=11.7 -c pytorch -c nvidia
<span class="w"> </span># Other conda packages:
<span class="w"> </span># conda install -y -n pytorch -c conda-forge rich tqdm
<span class="w"> </span>
<span class="w"> </span># Activate pre-existing environment.
<span class="w"> </span>conda activate pytorch
<span class="w"> </span>
<span class="gd">-</span>
<span class="gd">-# Stage dataset into $SLURM_TMPDIR</span>
<span class="gd">-mkdir -p $SLURM_TMPDIR/data</span>
<span class="gd">-ln -s /network/datasets/cifar10/cifar-10-python.tar.gz $SLURM_TMPDIR/data/</span>
<span class="gi">+# Stage dataset into $SLURM_TMPDIR (only on the first worker of each node)</span>
<span class="gi">+srun --ntasks=$SLURM_JOB_NUM_NODES --ntasks-per-node=1 bash -c \</span>
<span class="gi">+   &#39;mkdir -p $SLURM_TMPDIR/data &amp;&amp; ln -s /network/datasets/cifar10/cifar-10-python.tar.gz $SLURM_TMPDIR/data/&#39;</span>
<span class="w"> </span>
<span class="w"> </span># Get a unique port for this job based on the job ID
<span class="w"> </span>export MASTER_PORT=$(expr 10000 + $(echo -n $SLURM_JOBID | tail -c 4))
<span class="gd">-export MASTER_ADDR=&quot;127.0.0.1&quot;</span>
<span class="gi">+export MASTER_ADDR=$(scontrol show hostnames &quot;$SLURM_JOB_NODELIST&quot; | head -n 1)</span>
<span class="w"> </span>
<span class="w"> </span># Fixes issues with MIG-ed GPUs with versions of PyTorch &lt; 2.0
<span class="w"> </span>unset CUDA_VISIBLE_DEVICES
<span class="w"> </span>
<span class="w"> </span># Execute Python script in each task (one per GPU)
<span class="w"> </span>srun python main.py
</pre></div>
</div>
<p><strong>main.py</strong></p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="w"> </span># distributed/002_multi_gpu/main.py -&gt; distributed/003_multi_node/main.py
<span class="w"> </span>&quot;&quot;&quot;Multi-GPU Training example.&quot;&quot;&quot;
<span class="w"> </span>import logging
<span class="w"> </span>import os
<span class="gi">+from datetime import timedelta</span>
<span class="w"> </span>from pathlib import Path
<span class="w"> </span>
<span class="w"> </span>import rich.logging
<span class="w"> </span>import torch
<span class="w"> </span>import torch.distributed
<span class="w"> </span>from torch import Tensor, nn
<span class="w"> </span>from torch.distributed import ReduceOp
<span class="w"> </span>from torch.nn import functional as F
<span class="w"> </span>from torch.utils.data import DataLoader, random_split
<span class="w"> </span>from torch.utils.data.distributed import DistributedSampler
<span class="w"> </span>from torchvision import transforms
<span class="w"> </span>from torchvision.datasets import CIFAR10
<span class="w"> </span>from torchvision.models import resnet18
<span class="w"> </span>from tqdm import tqdm
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>def main():
<span class="w"> </span>    training_epochs = 10
<span class="w"> </span>    learning_rate = 5e-4
<span class="w"> </span>    weight_decay = 1e-4
<span class="w"> </span>    batch_size = 128  # NOTE: This is the &quot;local&quot; batch size, per-GPU.
<span class="w"> </span>
<span class="w"> </span>    # Check that the GPU is available
<span class="w"> </span>    assert torch.cuda.is_available() and torch.cuda.device_count() &gt; 0
<span class="gd">-    rank, world_size = setup()</span>
<span class="gi">+    rank, world_size, local_rank = setup()</span>
<span class="w"> </span>    is_master = rank == 0
<span class="gd">-    device = torch.device(&quot;cuda&quot;, rank)</span>
<span class="gi">+    is_local_master = local_rank == 0</span>
<span class="gi">+    device = torch.device(&quot;cuda&quot;, local_rank)</span>
<span class="w"> </span>
<span class="w"> </span>    # Setup logging (optional, but much better than using print statements)
<span class="w"> </span>    logging.basicConfig(
<span class="w"> </span>        level=logging.INFO,
<span class="w"> </span>        format=f&quot;[{rank}/{world_size}] %(name)s - %(message)s &quot;,
<span class="w"> </span>        handlers=[rich.logging.RichHandler(markup=True)],  # Very pretty, uses the `rich` package.
<span class="w"> </span>    )
<span class="w"> </span>
<span class="w"> </span>    logger = logging.getLogger(__name__)
<span class="gd">-    logger.info(f&quot;World size: {world_size}, global rank: {rank}&quot;)</span>
<span class="gi">+    logger.info(f&quot;World size: {world_size}, global rank: {rank}, local rank: {local_rank}&quot;)</span>
<span class="w"> </span>
<span class="w"> </span>    # Create a model and move it to the GPU.
<span class="w"> </span>    model = resnet18(num_classes=10)
<span class="w"> </span>    model.to(device=device)
<span class="w"> </span>
<span class="w"> </span>    # Wrap the model with DistributedDataParallel
<span class="w"> </span>    # (See https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel)
<span class="gd">-    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank], output_device=rank)</span>
<span class="gi">+    model = nn.parallel.DistributedDataParallel(</span>
<span class="gi">+        model, device_ids=[local_rank], output_device=local_rank</span>
<span class="gi">+    )</span>
<span class="w"> </span>
<span class="w"> </span>    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
<span class="w"> </span>
<span class="w"> </span>    # Setup CIFAR10
<span class="w"> </span>    num_workers = get_num_workers()
<span class="gi">+</span>
<span class="w"> </span>    dataset_path = Path(os.environ.get(&quot;SLURM_TMPDIR&quot;, &quot;.&quot;)) / &quot;data&quot;
<span class="w"> </span>    train_dataset, valid_dataset, test_dataset = make_datasets(
<span class="gd">-        str(dataset_path), is_master=is_master</span>
<span class="gi">+        str(dataset_path), is_master=is_local_master</span>
<span class="w"> </span>    )
<span class="w"> </span>
<span class="w"> </span>    # Restricts data loading to a subset of the dataset exclusive to the current process
<span class="w"> </span>    train_sampler = DistributedSampler(dataset=train_dataset, shuffle=True)
<span class="w"> </span>    valid_sampler = DistributedSampler(dataset=valid_dataset, shuffle=False)
<span class="w"> </span>    test_sampler = DistributedSampler(dataset=test_dataset, shuffle=False)
<span class="w"> </span>
<span class="w"> </span>    # NOTE: Here `batch_size` is still the &quot;local&quot; (per-gpu) batch size.
<span class="w"> </span>    # This way, the effective batch size scales directly with number of GPUs, no need to specify it
<span class="w"> </span>    # in advance. You might want to adjust the learning rate and other hyper-parameters though.
<span class="w"> </span>    if is_master:
<span class="w"> </span>        logger.info(f&quot;Effective batch size: {batch_size * world_size}&quot;)
<span class="w"> </span>    train_dataloader = DataLoader(
<span class="w"> </span>        train_dataset,
<span class="w"> </span>        batch_size=batch_size,
<span class="w"> </span>        num_workers=num_workers,
<span class="w"> </span>        shuffle=False,  # shuffling is now done in the sampler, not the dataloader.
<span class="w"> </span>        sampler=train_sampler,
<span class="w"> </span>    )
<span class="w"> </span>    valid_dataloader = DataLoader(
<span class="w"> </span>        valid_dataset,
<span class="w"> </span>        batch_size=batch_size,
<span class="w"> </span>        num_workers=num_workers,
<span class="w"> </span>        shuffle=False,
<span class="w"> </span>        sampler=valid_sampler,
<span class="w"> </span>    )
<span class="w"> </span>    test_dataloader = DataLoader(  # NOTE: Not used in this example.
<span class="w"> </span>        test_dataset,
<span class="w"> </span>        batch_size=batch_size,
<span class="w"> </span>        num_workers=num_workers,
<span class="w"> </span>        shuffle=False,
<span class="w"> </span>        sampler=test_sampler,
<span class="w"> </span>    )
<span class="w"> </span>
<span class="w"> </span>    # Checkout the &quot;checkpointing and preemption&quot; example for more info!
<span class="w"> </span>    logger.debug(&quot;Starting training from scratch.&quot;)
<span class="w"> </span>
<span class="w"> </span>    for epoch in range(training_epochs):
<span class="w"> </span>        logger.debug(f&quot;Starting epoch {epoch}/{training_epochs}&quot;)
<span class="w"> </span>
<span class="w"> </span>        # NOTE: Here we need to call `set_epoch` so the ordering is able to change at each epoch.
<span class="w"> </span>        train_sampler.set_epoch(epoch)
<span class="w"> </span>
<span class="w"> </span>        # Set the model in training mode (important for e.g. BatchNorm and Dropout layers)
<span class="w"> </span>        model.train()
<span class="w"> </span>
<span class="w"> </span>        # NOTE: using a progress bar from tqdm because it&#39;s nicer than using `print`.
<span class="w"> </span>        progress_bar = tqdm(
<span class="w"> </span>            total=len(train_dataloader),
<span class="w"> </span>            desc=f&quot;Train epoch {epoch}&quot;,
<span class="w"> </span>            disable=not is_master,
<span class="w"> </span>        )
<span class="w"> </span>
<span class="w"> </span>        # Training loop
<span class="w"> </span>        for batch in train_dataloader:
<span class="w"> </span>            # Move the batch to the GPU before we pass it to the model
<span class="w"> </span>            batch = tuple(item.to(device) for item in batch)
<span class="w"> </span>            x, y = batch
<span class="w"> </span>
<span class="w"> </span>            # Forward pass
<span class="w"> </span>            logits: Tensor = model(x)
<span class="w"> </span>
<span class="w"> </span>            local_loss = F.cross_entropy(logits, y)
<span class="w"> </span>
<span class="w"> </span>            optimizer.zero_grad()
<span class="w"> </span>            local_loss.backward()
<span class="w"> </span>            # NOTE: nn.DistributedDataParallel automatically averages the gradients across devices.
<span class="w"> </span>            optimizer.step()
<span class="w"> </span>
<span class="w"> </span>            # Calculate some metrics:
<span class="w"> </span>            # local metrics
<span class="w"> </span>            local_n_correct_predictions = logits.detach().argmax(-1).eq(y).sum()
<span class="w"> </span>            local_n_samples = logits.shape[0]
<span class="w"> </span>            local_accuracy = local_n_correct_predictions / local_n_samples
<span class="w"> </span>
<span class="w"> </span>            # &quot;global&quot; metrics: calculated with the results from all workers
<span class="w"> </span>            # NOTE: Creating new tensors to hold the &quot;global&quot; values, but this isn&#39;t required.
<span class="w"> </span>            n_correct_predictions = local_n_correct_predictions.clone()
<span class="w"> </span>            # Reduce the local metrics across all workers, sending the result to rank 0.
<span class="w"> </span>            torch.distributed.reduce(n_correct_predictions, dst=0, op=ReduceOp.SUM)
<span class="w"> </span>            # Actual (global) batch size for this step.
<span class="w"> </span>            n_samples = torch.as_tensor(local_n_samples, device=device)
<span class="w"> </span>            torch.distributed.reduce(n_samples, dst=0, op=ReduceOp.SUM)
<span class="w"> </span>            # Will store the average loss across all workers.
<span class="w"> </span>            loss = local_loss.clone()
<span class="w"> </span>            torch.distributed.reduce(loss, dst=0, op=ReduceOp.SUM)
<span class="w"> </span>            loss.div_(world_size)  # Report the average loss across all workers.
<span class="w"> </span>
<span class="w"> </span>            accuracy = n_correct_predictions / n_samples
<span class="w"> </span>
<span class="w"> </span>            logger.debug(f&quot;(local) Accuracy: {local_accuracy:.2%}&quot;)
<span class="w"> </span>            logger.debug(f&quot;(local) Loss: {local_loss.item()}&quot;)
<span class="w"> </span>            # NOTE: This would log the same values in all workers. Only logging on master:
<span class="w"> </span>            if is_master:
<span class="w"> </span>                logger.debug(f&quot;Accuracy: {accuracy.item():.2%}&quot;)
<span class="w"> </span>                logger.debug(f&quot;Average Loss: {loss.item()}&quot;)
<span class="w"> </span>
<span class="w"> </span>            # Advance the progress bar one step, and update the &quot;postfix&quot; () the progress bar. (nicer than just)
<span class="w"> </span>            progress_bar.update(1)
<span class="w"> </span>            progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy.item())
<span class="w"> </span>        progress_bar.close()
<span class="w"> </span>
<span class="w"> </span>        val_loss, val_accuracy = validation_loop(model, valid_dataloader, device)
<span class="w"> </span>        # NOTE: This would log the same values in all workers. Only logging on master:
<span class="w"> </span>        if is_master:
<span class="w"> </span>            logger.info(f&quot;Epoch {epoch}: Val loss: {val_loss:.3f} accuracy: {val_accuracy:.2%}&quot;)
<span class="w"> </span>
<span class="w"> </span>    print(&quot;Done!&quot;)
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>@torch.no_grad()
<span class="w"> </span>def validation_loop(model: nn.Module, dataloader: DataLoader, device: torch.device):
<span class="w"> </span>    model.eval()
<span class="w"> </span>
<span class="w"> </span>    total_loss = torch.as_tensor(0.0, device=device)
<span class="w"> </span>    n_samples = torch.as_tensor(0, device=device)
<span class="w"> </span>    correct_predictions = torch.as_tensor(0, device=device)
<span class="w"> </span>
<span class="w"> </span>    for batch in dataloader:
<span class="w"> </span>        batch = tuple(item.to(device) for item in batch)
<span class="w"> </span>        x, y = batch
<span class="w"> </span>
<span class="w"> </span>        logits: Tensor = model(x)
<span class="w"> </span>        loss = F.cross_entropy(logits, y)
<span class="w"> </span>
<span class="w"> </span>        batch_n_samples = x.shape[0]
<span class="w"> </span>        batch_correct_predictions = logits.argmax(-1).eq(y).sum()
<span class="w"> </span>
<span class="w"> </span>        total_loss += loss
<span class="w"> </span>        n_samples += batch_n_samples
<span class="w"> </span>        correct_predictions += batch_correct_predictions
<span class="w"> </span>
<span class="w"> </span>    # Sum up the metrics we gathered on each worker before returning the overall val metrics.
<span class="w"> </span>    torch.distributed.all_reduce(total_loss, op=torch.distributed.ReduceOp.SUM)
<span class="w"> </span>    torch.distributed.all_reduce(correct_predictions, op=torch.distributed.ReduceOp.SUM)
<span class="w"> </span>    torch.distributed.all_reduce(n_samples, op=torch.distributed.ReduceOp.SUM)
<span class="w"> </span>
<span class="w"> </span>    accuracy = correct_predictions / n_samples
<span class="w"> </span>    return total_loss, accuracy
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>def setup():
<span class="w"> </span>    assert torch.distributed.is_available()
<span class="w"> </span>    print(&quot;PyTorch Distributed available.&quot;)
<span class="w"> </span>    print(&quot;  Backends:&quot;)
<span class="w"> </span>    print(f&quot;    Gloo: {torch.distributed.is_gloo_available()}&quot;)
<span class="w"> </span>    print(f&quot;    NCCL: {torch.distributed.is_nccl_available()}&quot;)
<span class="w"> </span>    print(f&quot;    MPI:  {torch.distributed.is_mpi_available()}&quot;)
<span class="w"> </span>
<span class="gi">+    # NOTE: the env:// init method uses FileLocks, which sometimes causes deadlocks due to the</span>
<span class="gi">+    # distributed filesystem configuration on the Mila cluster.</span>
<span class="gi">+    # For multi-node jobs, use the TCP init method instead.</span>
<span class="gi">+    master_addr = os.environ[&quot;MASTER_ADDR&quot;]</span>
<span class="gi">+    master_port = os.environ[&quot;MASTER_PORT&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    # Default timeout is 30 minutes. Reducing the timeout here, so the job fails quicker if there&#39;s</span>
<span class="gi">+    # a communication problem between nodes.</span>
<span class="gi">+    timeout = timedelta(seconds=60)</span>
<span class="gi">+</span>
<span class="w"> </span>    # DDP Job is being run via `srun` on a slurm cluster.
<span class="w"> </span>    rank = int(os.environ[&quot;SLURM_PROCID&quot;])
<span class="gi">+    local_rank = int(os.environ[&quot;SLURM_LOCALID&quot;])</span>
<span class="w"> </span>    world_size = int(os.environ[&quot;SLURM_NTASKS&quot;])
<span class="w"> </span>
<span class="w"> </span>    # SLURM var -&gt; torch.distributed vars in case needed
<span class="w"> </span>    # NOTE: Setting these values isn&#39;t exactly necessary, but some code might assume it&#39;s
<span class="w"> </span>    # being run via torchrun or torch.distributed.launch, so setting these can be a good idea.
<span class="w"> </span>    os.environ[&quot;RANK&quot;] = str(rank)
<span class="gi">+    os.environ[&quot;LOCAL_RANK&quot;] = str(local_rank)</span>
<span class="w"> </span>    os.environ[&quot;WORLD_SIZE&quot;] = str(world_size)
<span class="w"> </span>
<span class="w"> </span>    torch.distributed.init_process_group(
<span class="w"> </span>        backend=&quot;nccl&quot;,
<span class="gd">-        init_method=&quot;env://&quot;,</span>
<span class="gi">+        init_method=f&quot;tcp://{master_addr}:{master_port}&quot;,</span>
<span class="gi">+        timeout=timeout,</span>
<span class="w"> </span>        world_size=world_size,
<span class="w"> </span>        rank=rank,
<span class="w"> </span>    )
<span class="gd">-    return rank, world_size</span>
<span class="gi">+    return rank, world_size, local_rank</span>
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>def make_datasets(
<span class="w"> </span>    dataset_path: str,
<span class="w"> </span>    is_master: bool,
<span class="w"> </span>    val_split: float = 0.1,
<span class="w"> </span>    val_split_seed: int = 42,
<span class="w"> </span>):
<span class="w"> </span>    &quot;&quot;&quot;Returns the training, validation, and test splits for CIFAR10.
<span class="w"> </span>
<span class="w"> </span>    NOTE: We don&#39;t use image transforms here for simplicity.
<span class="w"> </span>    Having different transformations for train and validation would complicate things a bit.
<span class="w"> </span>    Later examples will show how to do the train/val/test split properly when using transforms.
<span class="w"> </span>
<span class="w"> </span>    NOTE: Only the master process (rank-0) downloads the dataset if necessary.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    # - Master: Download (if necessary) THEN Barrier
<span class="w"> </span>    # - others: Barrier THEN *NO* Download
<span class="w"> </span>    if not is_master:
<span class="w"> </span>        # Wait for the master process to finish downloading (reach the barrier below)
<span class="w"> </span>        torch.distributed.barrier()
<span class="w"> </span>    train_dataset = CIFAR10(
<span class="w"> </span>        root=dataset_path, transform=transforms.ToTensor(), download=is_master, train=True
<span class="w"> </span>    )
<span class="w"> </span>    test_dataset = CIFAR10(
<span class="w"> </span>        root=dataset_path, transform=transforms.ToTensor(), download=is_master, train=False
<span class="w"> </span>    )
<span class="w"> </span>    if is_master:
<span class="w"> </span>        # Join the workers waiting in the barrier above. They can now load the datasets from disk.
<span class="w"> </span>        torch.distributed.barrier()
<span class="w"> </span>    # Split the training dataset into a training and validation set.
<span class="w"> </span>    n_samples = len(train_dataset)
<span class="w"> </span>    n_valid = int(val_split * n_samples)
<span class="w"> </span>    n_train = n_samples - n_valid
<span class="w"> </span>    train_dataset, valid_dataset = random_split(
<span class="w"> </span>        train_dataset, (n_train, n_valid), torch.Generator().manual_seed(val_split_seed)
<span class="w"> </span>    )
<span class="w"> </span>    return train_dataset, valid_dataset, test_dataset
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>def get_num_workers() -&gt; int:
<span class="w"> </span>    &quot;&quot;&quot;Gets the optimal number of DatLoader workers to use in the current job.&quot;&quot;&quot;
<span class="w"> </span>    if &quot;SLURM_CPUS_PER_TASK&quot; in os.environ:
<span class="w"> </span>        return int(os.environ[&quot;SLURM_CPUS_PER_TASK&quot;])
<span class="w"> </span>    if hasattr(os, &quot;sched_getaffinity&quot;):
<span class="w"> </span>        return len(os.sched_getaffinity(0))
<span class="w"> </span>    return torch.multiprocessing.cpu_count()
<span class="w"> </span>
<span class="w"> </span>
<span class="w"> </span>if __name__ == &quot;__main__&quot;:
<span class="w"> </span>    main()
</pre></div>
</div>
<p><strong>Running this example</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sbatch<span class="w"> </span>job.sh
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Theory_cluster.html" class="btn btn-neutral float-left" title="What is a computer cluster?" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Acknowledgement.html" class="btn btn-neutral float-right" title="Acknowledging Mila" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
<script type="text/javascript">
  window.onload = function() {
      $(".toggle > *").hide();
      $(".toggle .header").show();
      $(".toggle .header").click(function() {
          $(this).parent().children().not(".header").toggle(400);
          $(this).parent().children(".header").toggleClass("open");
      })
  };
</script>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>